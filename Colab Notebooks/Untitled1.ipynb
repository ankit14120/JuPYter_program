{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwOuqk/5Guqtq3yMIaIpln"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EjL963dd3hO5","executionInfo":{"status":"error","timestamp":1683054552628,"user_tz":-330,"elapsed":5990,"user":{"displayName":"Suvrana","userId":"12824155564455976994"}},"outputId":"cd1a7b1e-37f6-466e-8206-ffba990dcb2c","colab":{"base_uri":"https://localhost:8080/","height":401}},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1563b9c93d42>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (/usr/local/lib/python3.10/dist-packages/keras/preprocessing/sequence.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.applications.xception import Xception\n","from keras.models import load_model\n","from pickle import load\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import argparse\n","\n","\n","ap = argparse.ArgumentParser()\n","ap.add_argument('-i', '--image', required=True, help=\"Image Path\")\n","args = vars(ap.parse_args())\n","img_path = args['image']\n","\n","def extract_features(filename, model):\n","        try:\n","            image = Image.open(filename)\n","            \n","        except:\n","            print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n","        image = image.resize((299,299))\n","        image = np.array(image)\n","        # for images that has 4 channels, we convert them into 3 channels\n","        if image.shape[2] == 4: \n","            image = image[..., :3]\n","        image = np.expand_dims(image, axis=0)\n","        image = image/127.5\n","        image = image - 1.0\n","        feature = model.predict(image)\n","        return feature\n","\n","def word_for_id(integer, tokenizer):\n"," for word, index in tokenizer.word_index.items():\n","     if index == integer:\n","         return word\n"," return None\n","\n","\n","def generate_desc(model, tokenizer, photo, max_length):\n","    in_text = 'start'\n","    for i in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        pred = model.predict([photo,sequence], verbose=0)\n","        pred = np.argmax(pred)\n","        word = word_for_id(pred, tokenizer)\n","        if word is None:\n","            break\n","        in_text += ' ' + word\n","        if word == 'end':\n","            break\n","    return in_text\n","\n","\n","#path = 'Flicker8k_Dataset/111537222_07e56d5a30.jpg'\n","max_length = 32\n","tokenizer = load(open(\"tokenizer.p\",\"rb\"))\n","model = load_model('models/model_9.h5')\n","xception_model = Xception(include_top=False, pooling=\"avg\")\n","\n","photo = extract_features(img_path, xception_model)\n","img = Image.open(img_path)\n","\n","description = generate_desc(model, tokenizer, photo, max_length)\n","print(\"\\n\\n\")\n","print(description)\n","plt.imshow(img)\n","\n","\n"]}]}